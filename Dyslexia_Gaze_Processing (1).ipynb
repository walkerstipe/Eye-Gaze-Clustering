{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Structure of the notebook:\n",
    "    #many functions are defined\n",
    "        #I put the function descriptions in their definitions\n",
    "    #all the functions are called from a single cell, (last cell)\n",
    "    #entire notebook can be run remotely with: \n",
    "        #%run C:\\\\Users\\\\walke\\\\Downloads\\\\Sample_loading_gaze_data_DBSCAN_Agglomerative-Looping.ipynb\n",
    "        #NOTE: jupyter notebooks currently does not show plots via this method\n",
    "    #Everything, I believe, is as it should be EXCEPT for one cell where \n",
    "        #the handling of '0' in the dataset is returning Nulls\n",
    "        #I have instituted a temporary solution particular to each dataset\n",
    "        #But this is the key problem I will tackle so that we can run the code\n",
    "        #on all the subject with ease\n",
    "        \n",
    "#imports should all be here\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy import stats\n",
    "import os\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaze_stamp is just combining the gaze points and timestamp into a single array\n",
    "def initialize_gaze_stamp():\n",
    "    gaze_stamp = np.ndarray(shape=(3,len(gaze.transpose())), dtype=np.float64, order='C')\n",
    "    #create single array with both xy gaze and timestamp\n",
    "    gaze_stamp[0:2] = gaze\n",
    "    gaze_stamp[2] = timestamp\n",
    "    return gaze_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#basic visualization of gaze_stamp\n",
    "def initial_vis():\n",
    "    # Example visualizations, histograms for gaze points. \n",
    "    f, axarr = plt.subplots(1, 2,sharex=True, figsize=(20,5))\n",
    "\n",
    "    spidx=0 # set subplot index.\n",
    "\n",
    "    x_hist = axarr[spidx].hist(gaze[0,:],100) \n",
    "    axarr[spidx].set_title('Histogram of x-coordinates')\n",
    "    axarr[spidx].set_xlabel('X-coordinates')\n",
    "    axarr[spidx].set_ylabel('frequency')\n",
    "\n",
    "    spidx=1 # set subplot index.\n",
    "\n",
    "    x_hist = axarr[spidx].hist(gaze[1,:],100) \n",
    "    axarr[spidx].set_title('Histogram of y-coordinates')\n",
    "    axarr[spidx].set_xlabel('Y-coordinates')\n",
    "    axarr[spidx].set_ylabel('frequency')\n",
    "\n",
    "    # Display gaze map.\n",
    "\n",
    "    gaze_tp = gaze.transpose()\n",
    "    X = gaze_stamp.transpose()\n",
    "    plt.figure(figsize=(15,10))  # just to specify the figure size \n",
    "    plt.scatter(X[:,0],-X[:,1])  # reverse y coordinates since screen position start from upper left corner.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dbscan on gaze_stamp\n",
    "def my_dbscan():\n",
    "    db = DBSCAN(eps=0.3, min_samples=10).fit(gaze.transpose())\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "\n",
    "    # #############################################################################\n",
    "    # Plot result\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Black removed and is used for noise instead.\n",
    "    unique_labels = set(labels)\n",
    "    colors = [plt.cm.Spectral(each)\n",
    "              for each in np.linspace(0, 1, len(unique_labels))]\n",
    "    for k, col in zip(unique_labels, colors):\n",
    "        if k == -1:\n",
    "            # Black used for noise.\n",
    "            col = [0, 0, 0, 1]\n",
    "        class_member_mask = (labels == k)\n",
    "\n",
    "        xy = gaze_stamp.transpose()[class_member_mask & core_samples_mask]\n",
    "        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "                 markeredgecolor='k', markersize=25)\n",
    "\n",
    "        xy = gaze_stamp.transpose()[class_member_mask & ~core_samples_mask]\n",
    "        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "                 markeredgecolor='k', markersize=2)\n",
    "\n",
    "    plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "    plt.show()\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add dbscan label to give us gsln, (n denotes removing noise points. l stands for label)\n",
    "def create_gsln(labels):\n",
    "    #gsl == gaze, timeStamp, and label\n",
    "    gsl = np.ndarray(shape=(4,len(gaze.transpose())), dtype=np.float64, order='C')\n",
    "\n",
    "    gsl[3] = labels\n",
    "    gsl[2] = timestamp\n",
    "    gsl[0:2] = gaze\n",
    "    gsln = gsl[:,gsl[3,:]!=-1]\n",
    "    return gsln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#agglomerative clustering on glsn\n",
    "def agglom_clustering(gsln):\n",
    "\n",
    "    X = gsln.transpose()\n",
    "\n",
    "    connectivity=None\n",
    "    n_clusters=50\n",
    "    #we probably only need to use one of these methods?\n",
    "    for index, linkage in enumerate(('average',\n",
    "                                         'complete',\n",
    "                                         'ward',)):\n",
    "        plt.subplot(1, 4, index + 1)\n",
    "        model = AgglomerativeClustering(linkage=linkage,\n",
    "                                        connectivity=None,\n",
    "                                        n_clusters=n_clusters)\n",
    "        t0 = time.time()\n",
    "        model.fit(X)\n",
    "        elapsed_time = time.time() - t0\n",
    "        plt.scatter(X[:, 0], X[:, 1], c=model.labels_,\n",
    "                    cmap=plt.cm.nipy_spectral)\n",
    "        plt.axis('equal')\n",
    "        plt.axis('on')\n",
    "\n",
    "        plt.subplots_adjust(bottom=0, top=.89, wspace=0,\n",
    "                            left=0, right=4)\n",
    "    plt.show()\n",
    "    return model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots 1 agglomerative result (gaze and label)\n",
    "def plot_one_agglom(gsla):\n",
    "    plt.subplot(1, 4, index + 1)\n",
    "    plt.scatter(gsla[0, :], gsla[1, :], c=gsla[3],\n",
    "                cmap=plt.cm.nipy_spectral)\n",
    "    plt.title('linkage=%s\\n(time %.2fs)' % (linkage, elapsed_time),\n",
    "              fontdict=dict(verticalalignment='top'))\n",
    "    plt.axis('equal')\n",
    "    plt.axis('off')\n",
    "    plt.subplots_adjust(bottom=-1, top=.89, wspace=0,\n",
    "                        left=-5, right=1)\n",
    "    plt.suptitle('n_cluster=%i, connectivity=%r' %\n",
    "                 (n_clusters, connectivity is not None), size=25)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#should be able to save various data types with various names\n",
    "def save_results(gsla, fn):\n",
    "    f_name = fn\n",
    "    gaze_agg_list = []\n",
    "    try:\n",
    "        with open(\"D:\\\\Documents\\\\My_Code\\\\Christoforos\\\\saved_results\\\\\" + f_name + \".txt\", \"rb\") as fp:   # Unpickling\n",
    "            gaze_agg_list = pickle.load(fp)\n",
    "            print('len of gaze_agg_list: ', len(gaze_agg_list))\n",
    "\n",
    "        #already have data at this point\n",
    "        with open(\"D:\\\\Documents\\\\My_Code\\\\Christoforos\\\\saved_results\\\\\" + f_name + \".txt\", \"wb\") as fp:   #Pickling\n",
    "            gaze_agg_list.append(gsla)\n",
    "            pickle.dump(gaze_agg_list, fp)\n",
    "        print(\"succesfully loaded previous data and added new data to it.\")\n",
    "        \n",
    "    except Exception: \n",
    "        print('nothing to open; saving first file: ')\n",
    "\n",
    "        with open(\"D:\\\\Documents\\\\My_Code\\\\Christoforos\\\\saved_results\\\\\" + f_name  + \".txt\", \"wb\") as fp:   #Pickling\n",
    "            print(\"gaze_agg_list should be empty: \", gaze_agg_list)\n",
    "            gaze_agg_list.append(gsla)\n",
    "            pickle.dump(gaze_agg_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#just to be sure we are not using old data \n",
    "def reset_save(file_name):\n",
    "    fn = file_name\n",
    "    dumby_list = []\n",
    "    with open(\"D:\\\\Documents\\\\My_Code\\\\Christoforos\\\\saved_results\\\\\" + fn + \".txt\", \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(dumby_list, fp)\n",
    "    print('WARNING!!! succesfully replaced file with dumby data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I am converting to np.array here as output. \n",
    "def load_results(file_name):\n",
    "    fn = file_name\n",
    "    var = []\n",
    "    with open(\"D:\\\\Documents\\\\My_Code\\\\Christoforos\\\\saved_results\\\\\" + fn + \".txt\", \"rb\") as fp:   # Unpickling\n",
    "        var = pickle.load(fp)\n",
    "    \n",
    "    var_arr = np.asarray(var)\n",
    "    var_arr  = var_arr[0]\n",
    "    \n",
    "    return var_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaze with dbscan labels\n",
    "def plt_dbscan_with_time(gsln):\n",
    "    #dbscan labels with time\n",
    "    sorted_dbscan_labels = sorted(gsln[3])\n",
    "    plt.scatter(gsln[2], sorted_dbscan_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaze with aglomerative labels\n",
    "def plt_agglom_with_time(gsla):\n",
    "    #agglomerative labels with time\n",
    "    sorted_agglom_labels = sorted(gsla[3])\n",
    "    plt.scatter(gsla[2],sorted_agglom_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_last_element(i, gsl_arr):\n",
    "    c = i\n",
    "    if i == 41:\n",
    "        print('erf')\n",
    "    for c in range(i, len(gsl_arr[3]) - i):\n",
    "        if gsl_arr[3,i] == gsl_arr[3,c]:\n",
    "            max_index = c\n",
    "    try:\n",
    "        return max_index\n",
    "    except:\n",
    "        return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_element(i, gsl_arr):\n",
    "    c = i\n",
    "    if i == 41:\n",
    "        print('hjg')\n",
    "    for c in range( len(gsl_arr[3]) ):\n",
    "        if gsl_arr[3,i] == gsl_arr[3,c]:\n",
    "            min_index = cX\n",
    "            return min_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes any overlap in labels, (Ensures they are grouped with no mixing)\n",
    "#THE ASSIGNMENT ERROR IS HERE\n",
    "    #gsl_d[3,temp_min:temp_max] = gsl_d[3,i] appears to be the issue\n",
    "        #how to resolve...?\n",
    "def remove_overlap(gsl_arr):\n",
    "    gsl_d = np.copy(gsla)#temporary array\n",
    "\n",
    "    for i in range(len(gsl_d[3])):\n",
    "        if i + 2 < len(gsl_d[3]): #dont go out of bounds\n",
    "            temp_max = find_last_element(i, gsl_d)\n",
    "            temp_min = find_first_element(i, gsl_d)\n",
    "            #if gsl_d[3,i] == 14:\n",
    "                #print(temp_min, ' ', temp_max, ' ', i)\n",
    "#             if gsl_d[3,i] == 41:\n",
    "#                 print(temp_min, ' ', temp_max, ' ', i)\n",
    "            gsl_d[3,temp_min:temp_max] = gsl_d[3,i] \n",
    "#             if gsl_d[3,i] == 41:\n",
    "#                 print(temp_min, ' ', temp_max, ' ', i, 'AFTER ASSIGNMENT')\n",
    "    return gsl_d\n",
    "#tex = remove_overlap(gsla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label 14 goes till 14564, 41 starts at 14482\n",
    "    #so there is an overlap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_array(gsl_d, gsla):\n",
    "    confusion_value = []\n",
    "    confusion_label = []\n",
    "    for i in range(len(gsla[3])):\n",
    "        if gsl_d[3,i] != gsla[3,i]:\n",
    "            #print('im confused')\n",
    "            temp = [gsl_d[3,i]]\n",
    "            confusion_value.append(temp)\n",
    "            confusion_label.append(i)\n",
    "    confusion_value = np.asarray(confusion_value)\n",
    "    confusion_label = np.asarray(confusion_label)\n",
    "    confusion_array = np.column_stack((confusion_value, confusion_label))\n",
    "\n",
    "    return confusion_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets the last index with specific label, (this function is called iteravely)\n",
    "def get_last_time(label, gsl_arr, displace):\n",
    "    #print('label: ', label)\n",
    "    for i in reversed(range(len(gsl_arr[3]))): \n",
    "        #print(i)\n",
    "        if int(gsl_arr[3,i]) == int(label):\n",
    "#             if label == 41:\n",
    "#                 print('i: ', i, ' label: ', label, ' gls_arr: ', gsl_arr[3,i] )\n",
    "#                 max_index = i\n",
    "#                 print('\\n, type of return val: ', type(max_index - displace), max_index - displace)\n",
    "#                 return max_index - displace\n",
    "            max_index = i\n",
    "            return max_index - displace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Finally found the source of the issue (remove_overlap)\n",
    "# np.where( gsla_no_overlap[3] == 41 )\n",
    "# np.unique(gsla_no_overlap[3])\n",
    "# np.unique(gsla[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets the first index with specific label, (this function is called iteravely)\n",
    "def get_first_time(label, gsl_arr, displace): \n",
    "    for i in range( len(gsl_arr[3])):\n",
    "        if gsl_arr[3,i]  == 41:#int(label):\n",
    "            min_index = i\n",
    "#             print(gsl_arr[3,i])\n",
    "#             print('\\n type of return val: ', type(min_index - displace), min_index - displace, ' i: ', i, ' label: ', label)\n",
    "            return min_index + displace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(gsla_no_overlap[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gsla_no_overlap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-c51ff467c9df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mcombined_time\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs_time_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mabs_time_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcombined_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[0mcreate_absolute_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgsla_no_overlap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'gsla_no_overlap' is not defined"
     ]
    }
   ],
   "source": [
    "#gets the total duration for each label,\n",
    "#this is the portion of the code I am still working on, \n",
    "#something with indexes has gone wrong in the 'get_last_time'\n",
    "#it works except for when the label is 0 \n",
    "def create_absolute_time(gsl_arr, disp):\n",
    "    disp = int(disp)\n",
    "    gsla_no_overlap = np.copy(gsl_arr)\n",
    "    abs_time_value = []\n",
    "    abs_time_label = []\n",
    "    abs_time_time  = []\n",
    "    for i in range(50):\n",
    "        abs_time_value.append(get_last_time(i, gsla_no_overlap, disp))\n",
    "#         temp_gsla = np.copy(gsla_no_overlap)\n",
    "#         abs_time_value.append(get_first_time(i, np.flip(temp_gsla,1), disp))\n",
    "        abs_time_label.append(get_first_time(i, gsla_no_overlap, disp))  \n",
    "        abs_time_time.append(i)\n",
    "        \n",
    "    abs_time_value = np.asarray(abs_time_value)\n",
    "    abs_time_label = np.asarray(abs_time_label)\n",
    "    abs_time_time = np.asarray(abs_time_time)\n",
    "    abs_time_array = np.column_stack((abs_time_value, abs_time_label, abs_time_time))\n",
    "    combined_time = np.zeros(shape=(len(abs_time_array[:,0]),4), dtype=np.int32, order='C')\n",
    "    combined_time[:,:] = -1\n",
    "    #print(abs_time_array[:51,:3])\n",
    "    #combined_time[:,:3] = abs_time_array[:,:3]\n",
    "    try:\n",
    "        combined_time[:,:3] = abs_time_array[:,:3]\n",
    "        \n",
    "    except:#hardcoding temporary solutions on the current dataset\n",
    "           #I know this is heresy, I promise to fix it soon\n",
    "        print('None type found...')\n",
    "        if  abs_time_array[40,0] == None: \n",
    "            abs_time_array[40,0] = 31445\n",
    "            abs_time_array[40,1] = 31186\n",
    "        if  abs_time_array[25,0] == None:# 28415  28539\n",
    "            abs_time_array[25,0] = 28539\n",
    "            abs_time_array[25,1] = 28415\n",
    "        if  abs_time_array[21,0] == None:# 29685   30008\n",
    "            abs_time_array[21,0] = 30008\n",
    "            abs_time_array[21,1] = 29685\n",
    "        if  abs_time_array[41,0] == None:#   31837  31898\n",
    "            abs_time_array[41,0] = 31898\n",
    "            abs_time_array[41,1] = 31837\n",
    "        combined_time[:,:3] = abs_time_array[:,:3]\n",
    "    for i in range(len(abs_time_array)):\n",
    "        combined_time[i,3] = abs_time_array[i,0] - abs_time_array[i,1]\n",
    "    return combined_time\n",
    "create_absolute_time(gsla_no_overlap, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add each focus duration succesively \n",
    "def create_sequential_sum(arr):\n",
    "    arr = np.copy(arr)\n",
    "    my_sum = 0\n",
    "    for i in range(len(arr)):\n",
    "        my_sum = my_sum + arr[i,3]\n",
    "        arr[i,3] = my_sum\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is essentially the main, \"Class\", in that from here all other\n",
    "#functions are called and variables we need are kept here.  \n",
    "sid = [\"3\"]#,\"77\"] #[\"25\",\"78\"]\n",
    "#done subjects: 43, 78, 25,\n",
    "stim_idx = [\"1\",\"2\",\"3\",\"4\"] \n",
    "\n",
    "tmp_path = 'D:/Documents/My_Code/Christoforos/temp_data_for_Walker'\n",
    "directory = 'D:/Documents/My_Code/Christoforos/temp_data_for_Walker'\n",
    "\n",
    "for sid_ in sid:\n",
    "    for stim_ in stim_idx:\n",
    "        filename = \"D:/Documents/My_Code/Christoforos/temp_data_for_Walker/gaze_sid_\" + sid_ + \"_stimid_\" + stim_ + \".pickle\"\n",
    "        with open(filename, 'rb') as f:\n",
    "            timestamp, gaze, fixations  =  pickle.load(f)\n",
    "\n",
    "        gaze_stamp = initialize_gaze_stamp()\n",
    "        initial_vis()\n",
    "        dbscan_labels = my_dbscan()\n",
    "        gsln = create_gsln(dbscan_labels)\n",
    "        agg_labels = agglom_clustering(gsln)\n",
    "        gsla = gsln \n",
    "        gsla[3] = agg_labels\n",
    "\n",
    "        gsla_no_overlap = np.copy(remove_overlap(gsla))\n",
    "        \n",
    "        reset_save(\"abs_time_0_displace_\"+sid_+stim_)\n",
    "        disp = 0\n",
    "        abs_time = create_absolute_time(gsla_no_overlap, disp)\n",
    "        save_results(abs_time, \"abs_time_0_displace_\"+sid_+stim_)\n",
    "\n",
    "#This section can be run completeley on its own (No need to re-cluster etc.)\n",
    "\n",
    "#This section gets the absolute fixation times according to stimulus type\n",
    "    #also does some statistics and plotting. \n",
    "abs_time_list_difficult_rhyme = []\n",
    "abs_time_list_difficult_visual = []\n",
    "abs_time_list_easy_rhyme = []\n",
    "abs_time_list_easy_visual = []\n",
    "disp = \"0\" # or \"3\"\n",
    "sid = [\"43\",\"25\"]# [\"3\",\"25\",\"27\",\"29\",\"43\",\"77\",\"78\"]\n",
    "stim_idx = [\"1\",\"2\",\"3\",\"4\"]\n",
    "for sid_ in sid:\n",
    "    for stim_ in stim_idx:\n",
    "        if stim_ == \"1\":\n",
    "            abs_time_list_difficult_rhyme = []\n",
    "            abs_time_list_difficult_rhyme.append(load_results(\"abs_time_\"+disp+\"_displace_\"+sid_+stim_))\n",
    "            abs_time_arr_difficult_rhyme = np.asarray(abs_time_list_difficult_rhyme[0])   \n",
    "            abs_seq_difficult_rhyme  = create_sequential_sum(abs_time_arr_difficult_rhyme)#[0]\n",
    "            plt.scatter(abs_seq_difficult_rhyme[:,2], abs_seq_difficult_rhyme[:,3], marker='^')          \n",
    "        if stim_ == \"2\":             \n",
    "            abs_time_list_easy_rhyme = []\n",
    "            abs_time_list_easy_rhyme.append(load_results(\"abs_time_\"+disp+\"_displace_\"+sid_+stim_))\n",
    "            abs_time_arr_easy_rhyme = np.asarray(abs_time_list_easy_rhyme[0])   \n",
    "            abs_seq_easy_rhyme  = create_sequential_sum(abs_time_arr_easy_rhyme)#[0]\n",
    "            plt.scatter(abs_seq_easy_rhyme[:,2], abs_seq_easy_rhyme[:,3], marker='o')\n",
    "            plt.title('subject id: '+sid_+ ' rhyme confound')\n",
    "            plt.legend(('Difficult Test', 'Easy Test', 'Masked if < -0.5'),\n",
    "                   loc='upper left')\n",
    "            #this seperates the plots on the 'stim' attribute \n",
    "            plt.figure()\n",
    "            \n",
    "        if stim_ == \"3\":\n",
    "            abs_time_list_difficult_visual = []\n",
    "            abs_time_list_difficult_visual.append(load_results(\"abs_time_\"+disp+\"_displace_\"+sid_+stim_))\n",
    "            abs_time_arr_difficult_visual = np.asarray(abs_time_list_difficult_visual[0])   \n",
    "            abs_seq_difficult_visual  = create_sequential_sum(abs_time_arr_difficult_visual)#[0]\n",
    "            plt.scatter(abs_seq_difficult_visual[:,2], abs_seq_difficult_visual[:,3], marker='^')\n",
    "        if stim_ == \"4\":\n",
    "            abs_time_list_easy_visual = []\n",
    "            abs_time_list_easy_visual.append(load_results(\"abs_time_\"+disp+\"_displace_\"+sid_+stim_))\n",
    "            abs_time_arr_easy_visual = np.asarray(abs_time_list_easy_visual[0])   \n",
    "            abs_seq_easy_visual  = create_sequential_sum(abs_time_arr_easy_visual)#[0]\n",
    "            plt.scatter(abs_seq_easy_visual[:,2], abs_seq_easy_visual[:,3], marker='o')\n",
    "            plt.title('subject id: '+sid_+ ' visual confound')\n",
    "            plt.legend(('Difficult Test', 'Easy Test', 'Masked if < -0.5'),\n",
    "                   loc='upper left')\n",
    "            plt.figure()\n",
    "print(sid_,' rhyme: ', stats.ttest_ind(abs_seq_difficult_rhyme,abs_seq_easy_rhyme))\n",
    "print(sid_,' rhyme: ', stats.ttest_ind(abs_seq_difficult_visual,abs_seq_easy_visual),'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
